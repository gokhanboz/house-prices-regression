ğŸ  House Prices: Advanced Regression Techniques

ğŸ“˜ Proje HakkÄ±nda

Bu proje, Kaggle'daki "House Prices: Advanced Regression Techniques" yarÄ±ÅŸmasÄ± kapsamÄ±nda geliÅŸtirilmiÅŸtir. AmaÃ§, konut Ã¶zelliklerinden yola Ã§Ä±karak ev fiyatlarÄ±nÄ± tahmin eden etkili bir regresyon modeli oluÅŸturmaktÄ±r.

ğŸ”§ Uygulanan AdÄ±mlar

1. Veri YÃ¼kleme ve Temizleme

Eksik deÄŸer analizi yapÄ±ldÄ±.

Kategorik deÄŸiÅŸkenler "None" veya mod deÄŸeri ile dolduruldu.

SayÄ±sal veriler 0, ortanca veya mahalle medyanÄ± gibi mantÄ±klÄ± deÄŸerlerle tamamlandÄ±.

2. Ã–zellik MÃ¼hendisliÄŸi (Feature Engineering)

AÅŸaÄŸÄ±daki yeni sÃ¼tunlar oluÅŸturuldu:

TotalSF = TotalBsmtSF + 1stFlrSF + 2ndFlrSF

TotalBath = FullBath + 0.5HalfBath + BsmtFullBath + 0.5BsmtHalfBath

HasPool, HasFireplace, HasGarage gibi binary sÃ¼tunlar

3. One-Hot Encoding

TÃ¼m kategorik deÄŸiÅŸkenler sayÄ±sallaÅŸtÄ±rÄ±ldÄ±.

train/test veri setleri hizalandÄ±.

4. Modelleme

AÅŸaÄŸÄ±daki modeller denenmiÅŸtir:

Ridge Regression

Lasso Regression

Random Forest

XGBoost (en baÅŸarÄ±lÄ± model)

5. Ensemble

Ridge ve Lasso tahminleri ortalanarak basit bir ensemble modeli denendi.

ğŸ§  SonuÃ§lar

Ä°lk skor (baseline): 11.44

XGBoost modelinden sonra: 1.54

Feature engineering + XGBoost: 0.13379 (RMSLE)

ğŸ—‚ Dosya YapÄ±sÄ±

train.csv, test.csv â†’ ham veriler

submission_xgboost_features.csv â†’ son tahmin sonucu

notebook.ipynb veya main.py â†’ tÃ¼m analiz ve modelleme adÄ±mlarÄ±

README.md â†’ proje Ã¶zeti

ğŸš€ KullanÄ±lan AraÃ§lar

Python (pandas, numpy, scikit-learn, xgboost)

Jupyter Notebook

Kaggle veri seti

ğŸ“Œ Notlar

Bu proje, regresyon problemleri iÃ§in veriye dayalÄ± dÃ¼ÅŸÃ¼nme, Ã¶zellik mÃ¼hendisliÄŸi ve model tuning becerilerini geliÅŸtirmek amacÄ±yla yapÄ±lmÄ±ÅŸtÄ±r.